{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_numeric_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path= '../../datasets/main_data/bank-additional-full.csv'\n",
    "full_bank = pd.read_csv(path, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Module Data.py codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting data.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile data.py \n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as  np\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import os\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "\n",
    "def load_data(path=\"\", sep=\",\", cols_to_drop=[]):\n",
    "    data = pd.read_csv(path, sep)\n",
    "    for col in cols_to_drop:\n",
    "        data.drop(col, axis=1, inplace=True)\n",
    "    return data\n",
    "\n",
    "def check_outliers(data, show_plot=False, save_img=os.getcwd()+'/outliers.png'):\n",
    "    \n",
    "    \"\"\"\n",
    "    This functions checks for columns with outlers using the IQR method\n",
    "    \n",
    "    It accespts as argmuent a dataset. \n",
    "    show_plot can be set to True to output pairplots of outlier columns    \n",
    "    \"\"\"\n",
    "    \n",
    "    outliers = [] \n",
    "    Q1 = data.quantile(0.25)  \n",
    "    Q3 = data.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    num_data = data.select_dtypes(include='number')\n",
    "    result = dict ((((num_data < (Q1 - 1.5 * IQR)) | (num_data > (Q3 + 1.5 * IQR)))==True).any())\n",
    "    #data[(data[col] >= high)|(data[col] <= low)].index\n",
    "    index = data[(num_data < Q1 - 1.5 * IQR) | (num_data > Q3 + 1.5 * IQR)].index\n",
    "    for k,v in result.items():\n",
    "        if v == True:  \n",
    "            outliers.append(k)\n",
    "    if show_plot:\n",
    "        pair_plot = sns.pairplot(data[outliers]);\n",
    "        print(f'{result},\\n\\n Visualization of outlier columns')\n",
    "        plt.savefig(fname=save_img, format='png')\n",
    "        return pair_plot\n",
    "    else:\n",
    "        return data.loc[index, outliers]\n",
    "    \n",
    "    \n",
    "\n",
    "def treat_outliers(data, type='median_replace'):\n",
    "    \n",
    "    \"\"\"\n",
    "    This treat outliers using any ofthses 3 methods as specified by user\n",
    "    \n",
    "        1. median_replace -  median replacement\n",
    "        \n",
    "        2. quant_floor - quantile flooring\n",
    "        \n",
    "        3. trim - trimming \n",
    "        \n",
    "        4. log_transform - log transformations\n",
    "    \n",
    "    The methods are some of the commont statistical methods in treating outler\n",
    "    columns\n",
    "    \n",
    "    By default treatment type is set to median replacement\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    if type == \"median_replace\":\n",
    "        \n",
    "        for col in data.columns.tolist():\n",
    "            if is_numeric_dtype(data[col]):\n",
    "                median = (data[col].quantile(0.50))\n",
    "                print(median)\n",
    "                q1 = data[col].quantile(0.25)\n",
    "                q3 = data[col].quantile(0.75)\n",
    "                iqr = q3 - q1\n",
    "                high = int(q3 + 1.5 * iqr) \n",
    "                low = int(q1 - 1.5 * iqr)\n",
    "                print(high, low, iqr)\n",
    "                print(col)\n",
    "                data[col] = np.where(data[col] > high, median, data[col])\n",
    "                data[col] = np.where(data[col] > high, median, data[col])        \n",
    "    \n",
    "    if type == \"quant_floor\":\n",
    "        \n",
    "        for col in data.columns.tolist():\n",
    "            if is_numeric_dtype(data[col]):\n",
    "                q_10 = data[col].quantile(0.5)\n",
    "                q_90 = data[col].quantile(0.95)\n",
    "                data[col] =  data[col] = np.where(data[col] < q_10, q_10 , data[col])\n",
    "                data[col] =  data[col] = np.where(data[col] > q_90, q_90 , data[col])\n",
    "            \n",
    "    if type == \"trim\":\n",
    "        \n",
    "        for col in data.columns.tolist():\n",
    "            low = .05\n",
    "            high = .95\n",
    "            quant_df = data.quantile([low, high])\n",
    "            for name in list(data.columns):\n",
    "                if is_numeric_dtype(data[name]):\n",
    "                    data = data[(data[name] >= quant_df.loc[low, name]) \n",
    "                        & (data[name] <= quant_df.loc[high, name])]\n",
    "            \n",
    "    if type == \"log_transform\":  \n",
    "        for col in data.columns.tolist():\n",
    "            if is_numeric_dtype(data[col]):\n",
    "                data[col] = data[col].map(lambda i: np.log(i) if i > 0 else 0)\n",
    "                \n",
    "    if type == \"isf\":\n",
    "        iso = IsolationForest(contamination=0.1)\n",
    "        yhat = iso.fit_predict(data.select_dtypes(exclude='object'))\n",
    "        #select all rows that are not outliers\n",
    "        mask = yhat != -1 \n",
    "        data = data[mask]\n",
    "        \n",
    "\n",
    "    return data \n",
    "\n",
    "\n",
    "def scale_data(data,scaler=RobustScaler()):\n",
    "    \n",
    "    \"\"\"\n",
    "    Specify scaler type, scaler type must have fit_transform as a method\n",
    "    \n",
    "    \"\"\"\n",
    "    data_scaled = scaler.fit_transform(data)\n",
    "    return data_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Module Plot.py codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting plot.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile plot.py \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "import os\n",
    "\n",
    "def plot_univariate (data, x=None, y=None, color='r',save=False,\n",
    "                title='New Chart', chart_type='hist', xlabel='', ylabel='',\n",
    "                    save_to=os.getcwd(), log_normalise=False):\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Make a univariate plot of any of these selcted types:\n",
    "    \n",
    "    1. bar - barchart\n",
    "    \n",
    "    2. hist - Histogram\n",
    "    \n",
    "    3. pie - Piechart\n",
    "    \n",
    "    4. count - Countplot\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    plt.subplots(figsize=(10,7))\n",
    "    plt.title(title, fontsize=18)\n",
    "    plt.xlabel(xlabel, fontsize=15)\n",
    "    plt.ylabel(ylabel, fontsize=15)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    \n",
    "    \n",
    "    if chart_type == 'hist':\n",
    "        if log_normalise:\n",
    "            data = np.log(data)\n",
    "        plot = sns.distplot(a=data, color=color)\n",
    "        if save:\n",
    "            plt.savefig(fname=save_to+f'/{title}.png', format='png')\n",
    "        \n",
    "    return plot\n",
    "\n",
    "def plot_bivariate(data, x=None, y=None, hue=None, \n",
    "                  color='r',save=False,\n",
    "                title='New Chart', chart_type='hist',\n",
    "                   xlabel='', ylabel='',\n",
    "                    save_to=os.getcwd(), img_name = \" \", \n",
    "                   palette={'use':False, \"size\":1}, log_normalise=False,\n",
    "                  kind_joint_plot = 'scatter', kind_pair_plot=\"scatter\", figsize=(10,7)):\n",
    "    \n",
    "    \"\"\"\n",
    "    Make a bivariate plot of any of the selcted types:\n",
    "    \n",
    "    1. bar - barchart\n",
    "    \n",
    "    2. scatter  - scatter plot\n",
    "    \n",
    "    3. cat  - catplot\n",
    "    \n",
    "    4. count - countplot\n",
    "    \n",
    "    5 joint - jointplot \n",
    "    \n",
    "    6  pair - pairplot\n",
    "    \n",
    "    7  corr - corr_plot\n",
    "    \n",
    "    When calling joint_plot:\n",
    "        \n",
    "        kind_joint_plot is default to `scatter`\n",
    "        other types include \"reg\", \"reside\", \"kde\", \"hex\"\n",
    "        \n",
    "    When calling pair_plot:\n",
    "        \n",
    "        kind_pair_plot is default to `scatter`\n",
    "        other types include 'reg'\n",
    "    \"\"\"\n",
    "    def plt_tweaks():\n",
    "        plt.subplots(figsize= figsize)\n",
    "        plt.title(title, fontsize=18)\n",
    "        plt.xlabel(xlabel, fontsize=15)\n",
    "        plt.ylabel(ylabel, fontsize=15)\n",
    "        plt.xticks(fontsize=12)\n",
    "        plt.yticks(fontsize=12)\n",
    "    \n",
    "    \n",
    "    # define helper functions\n",
    "    \n",
    "    def use_palette():\n",
    "        palettes = []\n",
    "#        palette_to_use=[]\n",
    "        if palette['use'] == True:\n",
    "            palette_to_use = [palettes[i] for i in range(palette['size'])]\n",
    "            \n",
    "            return palette_to_use\n",
    "\n",
    "    def log_norm():\n",
    "        if log_normalise and y != None:\n",
    "            y = np.log(y)\n",
    "        elif log_normalise and y == None:\n",
    "            data = np.log(data)\n",
    "            \n",
    "    def save_image():\n",
    "        if save:\n",
    "            if img_name != \" \":\n",
    "                plt.savefig(fname=save_to+\"/\"+img_name+'.png', format='png')\n",
    "            else:\n",
    "                plt.savefig(fname=save_to+f'/{title}.png', format='png')\n",
    "                \n",
    "        \n",
    "    # make plots\n",
    "    \n",
    "    if chart_type == \"joint\":\n",
    "        log_norm()\n",
    "        plot = sns.jointplot(x=x, y=y, data=data,\n",
    "                            height=6, ratio=5, space=0.2, kind=kind_joint_plot)\n",
    "        \n",
    "        save_image()\n",
    "        \n",
    "    if chart_type == \"pair\":\n",
    "       # try:\n",
    "        log_norm()\n",
    "        if palette['use'] == True:\n",
    "            palette_to_use = use_palette()\n",
    "            plot = sns.pairplot(data, palette=palette_to_use, \n",
    "                            kind= kind_pair_plot,height=3, aspect=1, hue=hue)\n",
    "        else:\n",
    "             plot = sns.pairplot(data, \n",
    "                            kind= kind_pair_plot,height=2.5, aspect=1, hue=hue, )\n",
    "        save_image()\n",
    "        \n",
    "    if chart_type  == \"corr\":\n",
    "        plt_tweaks()\n",
    "        corr_data = data.corr()\n",
    "        corr_plot = sns.heatmap(corr_data,annot=True, fmt='.2g', center=0) \n",
    "\n",
    "def plot_univariate (data, x=None, y=None, color='r',save=False,\n",
    "                title='New Chart', chart_type='hist', xlabel='', ylabel='',\n",
    "                    save_to=os.getcwd(), log_normalise=False):\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Make a univariate plot of any of these selcted types:\n",
    "    \n",
    "    1. bar - barchart\n",
    "    \n",
    "    2. hist - Histogram\n",
    "    \n",
    "    3. pie - Piechart \n",
    "    \n",
    "    4. count - Countplot\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    plt.subplots(figsize=(10,7))\n",
    "    plt.title(title, fontsize=18)\n",
    "    plt.xlabel(xlabel, fontsize=15)\n",
    "    plt.ylabel(ylabel, fontsize=15)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    \n",
    "    \n",
    "    if chart_type == 'hist':\n",
    "        if log_normalise:\n",
    "            data = np.log(data)\n",
    "        plot = sns.distplot(a=data, color=color)\n",
    "        if save:\n",
    "            plt.savefig(fname=save_to+f'/{title}.png', format='png')\n",
    "        \n",
    "    return plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Module Model.py Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model.py\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "\n",
    "def plot_pca_components(data):\n",
    "    pca = PCA().fit(data)\n",
    "    plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "    plt.xlabel('number of components')\n",
    "    plt.ylabel('cumulative explained variance');\n",
    "    \n",
    "def check_imbalance(data,label='', x=0.7, y=30000):\n",
    "    plt.subplots(figsize=(10,8))\n",
    "    data[label].value_counts().plot(kind='bar')\n",
    "    text = f'Class Imbalance Count:\\n\\n{data[label].value_counts().to_dict()}'\n",
    "    plt.text(x=x, y=y, s = text ,  fontsize=15)\n",
    "    \n",
    "def encode (data):\n",
    "    ohe = OneHotEncoder(sparse=False, handle_unknown='ignore', )\n",
    "    to_encode = data.select_dtypes(exclude='number')\n",
    "    if data.shape[1] > 1:\n",
    "        #ohe = MultiLabelBinarizer()\n",
    "        data.drop(to_encode.columns.tolist(), axis=1, inplace = True)\n",
    "        features_cat_encode = pd.DataFrame(ohe.fit_transform(to_encode))\n",
    "        data = data.merge(features_cat_encode, left_index=True, right_index=True)\n",
    "        #print(ohe.classes_) \n",
    "    else:\n",
    "        data = pd.DataFrame(ohe.fit_transform(to_encode))\n",
    "        print(ohe.categories_) \n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_termsheet_pred_model",
   "language": "python",
   "name": "venv_termsheet_pred_model"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
