{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "from pandas.api.types import is_numeric_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "path= '../../datasets/main_data/bank-additional-full.csv'\n",
    "full_bank = pd.read_csv(path, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Module Data.py codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as  np\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import os\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "\n",
    "def load_data(path=\"\", sep=\",\", cols_to_drop=[]):\n",
    "    data = pd.read_csv(path, sep)\n",
    "    for col in cols_to_drop:\n",
    "        data.drop(col, axis=1, inplace=True)\n",
    "    return data\n",
    "\n",
    "def check_outliers(data, show_plot=False, save_img=os.getcwd()+'/outliers.png'):\n",
    "    \n",
    "    \"\"\"\n",
    "    This functions checks for columns with outlers using the IQR method\n",
    "    \n",
    "    It accespts as argmuent a dataset. \n",
    "    show_plot can be set to True to output pairplots of outlier columns    \n",
    "    \"\"\"\n",
    "    \n",
    "    outliers = [] \n",
    "    Q1 = data.quantile(0.25)  \n",
    "    Q3 = data.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    num_data = data.select_dtypes(include='number')\n",
    "    result = dict ((((num_data < (Q1 - 1.5 * IQR)) | (num_data > (Q3 + 1.5 * IQR)))==True).any())\n",
    "    #data[(data[col] >= high)|(data[col] <= low)].index\n",
    "    index = data[(num_data < Q1 - 1.5 * IQR) | (num_data > Q3 + 1.5 * IQR)].index\n",
    "    for k,v in result.items():\n",
    "        if v == True:  \n",
    "            outliers.append(k)\n",
    "    if show_plot:\n",
    "        pair_plot = sns.pairplot(data[outliers]);\n",
    "        print(f'{result},\\n\\n Visualization of outlier columns')\n",
    "        plt.savefig(fname=save_img, format='png')\n",
    "        return pair_plot\n",
    "    else:\n",
    "        return data.loc[index, outliers]\n",
    "    \n",
    "    \n",
    "\n",
    "def treat_outliers(data, type='median_replace'):\n",
    "    \n",
    "    \"\"\"\n",
    "    This treat outliers using any ofthses 3 methods as specified by user\n",
    "    \n",
    "        1. median_replace -  median replacement\n",
    "        \n",
    "        2. quant_floor - quantile flooring\n",
    "        \n",
    "        3. trim - trimming \n",
    "        \n",
    "        4. log_transform - log transformations\n",
    "    \n",
    "    The methods are some of the commont statistical methods in treating outler\n",
    "    columns\n",
    "    \n",
    "    By default treatment type is set to median replacement\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    if type == \"median_replace\":\n",
    "        \n",
    "        for col in data.columns.tolist():\n",
    "            if is_numeric_dtype(data[col]):\n",
    "                median = (data[col].quantile(0.50))\n",
    "                print(median)\n",
    "                q1 = data[col].quantile(0.25)\n",
    "                q3 = data[col].quantile(0.75)\n",
    "                iqr = q3 - q1\n",
    "                high = int(q3 + 1.5 * iqr) \n",
    "                low = int(q1 - 1.5 * iqr)\n",
    "                print(high, low, iqr)\n",
    "                print(col)\n",
    "                data[col] = np.where(data[col] > high, median, data[col])\n",
    "                data[col] = np.where(data[col] > high, median, data[col])        \n",
    "    \n",
    "    if type == \"quant_floor\":\n",
    "        \n",
    "        for col in data.columns.tolist():\n",
    "            if is_numeric_dtype(data[col]):\n",
    "                q_10 = data[col].quantile(0.5)\n",
    "                q_90 = data[col].quantile(0.95)\n",
    "                data[col] =  data[col] = np.where(data[col] < q_10, q_10 , data[col])\n",
    "                data[col] =  data[col] = np.where(data[col] > q_90, q_90 , data[col])\n",
    "            \n",
    "    if type == \"trim\":\n",
    "        \n",
    "        for col in data.columns.tolist():\n",
    "            low = .05\n",
    "            high = .95\n",
    "            quant_df = data.quantile([low, high])\n",
    "            for name in list(data.columns):\n",
    "                if is_numeric_dtype(data[name]):\n",
    "                    data = data[(data[name] >= quant_df.loc[low, name]) \n",
    "                        & (data[name] <= quant_df.loc[high, name])]\n",
    "            \n",
    "    if type == \"log_transform\":  \n",
    "        for col in data.columns.tolist():\n",
    "            if is_numeric_dtype(data[col]):\n",
    "                data[col] = data[col].map(lambda i: np.log(i) if i > 0 else 0)\n",
    "                \n",
    "    if type == \"isf\":\n",
    "        iso = IsolationForest(contamination=0.1)\n",
    "        yhat = iso.fit_predict(data.select_dtypes(exclude='object'))\n",
    "        #select all rows that are not outliers\n",
    "        mask = yhat != -1 \n",
    "        data = data[mask]\n",
    "        \n",
    "\n",
    "    return data \n",
    "\n",
    "\n",
    "def scale_data(data,scaler=RobustScaler()):\n",
    "    \n",
    "    \"\"\"\n",
    "    Specify scaler type, scaler type must have fit_transform as a method\n",
    "    \n",
    "    \"\"\"\n",
    "    data_scaled = scaler.fit_transform(data)\n",
    "    return data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as  np\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import os\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "\n",
    "class PrepareData():\n",
    "    \n",
    "    def __repr__(self):\n",
    "        \n",
    "        return \"Used to prepare data for modelling\"\n",
    "    \n",
    "    def  __init__(self, path=\"\"):\n",
    "        self.path = path\n",
    "    \n",
    "    def load_data(self, path=\"\", sep=\",\", cols_to_drop=[]):\n",
    "        self.data = pd.read_csv(self.path, sep)\n",
    "        for col in cols_to_drop:\n",
    "            self.data.drop(col, axis=1, inplace=True)\n",
    "\n",
    "        return self.data \n",
    "\n",
    "\n",
    "    def check_outliers(self, data, show_plot=False, save_img=os.getcwd()+'/outliers.png'):\n",
    "        \n",
    "        self.data = data\n",
    "    \n",
    "        \"\"\"\n",
    "        This functions checks for columns with outlers using the IQR method\n",
    "\n",
    "        It accespts as argmuent a dataset. \n",
    "        show_plot can be set to True to output pairplots of outlier columns    \n",
    "        \"\"\"\n",
    "\n",
    "        outliers = [] \n",
    "        Q1 = self.data.quantile(0.25)  \n",
    "        Q3 = self.data.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        num_data = self.data.select_dtypes(include='number')\n",
    "        result = dict ((((num_data < (Q1 - 1.5 * IQR)) | (num_data > (Q3 + 1.5 * IQR)))==True).any())\n",
    "        #data[(data[col] >= high)|(data[col] <= low)].index\n",
    "        index = self.data[(num_data < Q1 - 1.5 * IQR) | (num_data > Q3 + 1.5 * IQR)].index\n",
    "        for k,v in result.items():\n",
    "            if v == True:  \n",
    "                outliers.append(k)\n",
    "        if show_plot:\n",
    "            pair_plot = sns.pairplot(self.data[outliers]);\n",
    "            print(f'{result},\\n\\n Visualization of outlier columns')\n",
    "            plt.savefig(fname=save_img, format='png')\n",
    "            return pair_plot\n",
    "        else:\n",
    "            return self.data.loc[index, outliers] \n",
    "        \n",
    "        \n",
    "    def treat_outliers(self, data, type='median_replace'):\n",
    "    \n",
    "        \"\"\"\n",
    "        This treat outliers using any ofthses 3 methods as specified by user\n",
    "\n",
    "            1. median_replace -  median replacement\n",
    "\n",
    "            2. quant_floor - quantile flooring\n",
    "\n",
    "            3. trim - trimming \n",
    "\n",
    "            4. log_transform - log transformations\n",
    "\n",
    "        The methods are some of the commont statistical methods in treating outler\n",
    "        columns\n",
    "\n",
    "        By default treatment type is set to median replacement\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if type == \"median_replace\":\n",
    "\n",
    "            for col in data.columns.tolist():\n",
    "                if is_numeric_dtype(data[col]):\n",
    "                    median = (data[col].quantile(0.50))\n",
    "                    print(median)\n",
    "                    q1 = data[col].quantile(0.25)\n",
    "                    q3 = data[col].quantile(0.75)\n",
    "                    iqr = q3 - q1\n",
    "                    high = int(q3 + 1.5 * iqr) \n",
    "                    low = int(q1 - 1.5 * iqr)\n",
    "                    print(high, low, iqr)\n",
    "                    print(col)\n",
    "                    data[col] = np.where(data[col] > high, median, data[col])\n",
    "                    data[col] = np.where(data[col] > high, median, data[col])        \n",
    "\n",
    "        if type == \"quant_floor\":\n",
    "\n",
    "            for col in data.columns.tolist():\n",
    "                if is_numeric_dtype(data[col]):\n",
    "                    q_10 = data[col].quantile(0.5)\n",
    "                    q_90 = data[col].quantile(0.95)\n",
    "                    data[col] =  data[col] = np.where(data[col] < q_10, q_10 , data[col])\n",
    "                    data[col] =  data[col] = np.where(data[col] > q_90, q_90 , data[col])\n",
    "\n",
    "        if type == \"trim\":\n",
    "\n",
    "            for col in data.columns.tolist():\n",
    "                low = .05\n",
    "                high = .95\n",
    "                quant_df = data.quantile([low, high])\n",
    "                for name in list(data.columns):\n",
    "                    if is_numeric_dtype(data[name]):\n",
    "                        data = data[(data[name] >= quant_df.loc[low, name]) \n",
    "                            & (data[name] <= quant_df.loc[high, name])]\n",
    "\n",
    "        if type == \"log_transform\":  \n",
    "            for col in data.columns.tolist():\n",
    "                if is_numeric_dtype(data[col]):\n",
    "                    data[col] = data[col].map(lambda i: np.log(i) if i > 0 else 0)\n",
    "\n",
    "        if type == \"isf\":\n",
    "            iso = IsolationForest(contamination=0.1)\n",
    "            yhat = iso.fit_predict(data.select_dtypes(exclude='object'))\n",
    "            #select all rows that are not outliers\n",
    "            mask = yhat != -1 \n",
    "            data = data[mask]\n",
    "\n",
    "\n",
    "        return data \n",
    "    \n",
    "    \n",
    "    def split_data_single(data, target_cols=[]):\n",
    "    \n",
    "        features = data.drop(columns=target_cols, axis=1) \n",
    "\n",
    "        target   = pd.DataFrame(data[target_cols])\n",
    "\n",
    "        return features, target\n",
    "    \n",
    "    \n",
    "    def encode (self, data):\n",
    "        \n",
    "        ohe = OneHotEncoder(sparse=False, handle_unknown='ignore', )\n",
    "        to_encode = data.select_dtypes(exclude='number')\n",
    "        if data.shape[1] > 1:\n",
    "            #ohe = MultiLabelBinarizer()\n",
    "            data.drop(to_encode.columns.tolist(), axis=1, inplace = True)\n",
    "            features_cat_encode = pd.DataFrame(ohe.fit_transform(to_encode))\n",
    "            data = data.merge(features_cat_encode, left_index=True, right_index=True)\n",
    "            #print(ohe.classes_) \n",
    "        else:\n",
    "            data = pd.DataFrame(ohe.fit_transform(to_encode))\n",
    "            print(ohe.categories_) \n",
    "        return data\n",
    "\n",
    "\n",
    "    def scale_data(self, data,scaler=RobustScaler()):\n",
    "\n",
    "        \"\"\"\n",
    "        Specify scaler type, scaler type must have fit_transform as a method\n",
    "\n",
    "        \"\"\"\n",
    "        data_scaled = scaler.fit_transform(data)\n",
    "        \n",
    "        return data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = split_data_single(data, target_cols=['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40544</th>\n",
       "      <td>33</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>tue</td>\n",
       "      <td>4</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>94.027</td>\n",
       "      <td>-38.3</td>\n",
       "      <td>0.886</td>\n",
       "      <td>4991.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40545</th>\n",
       "      <td>31</td>\n",
       "      <td>admin.</td>\n",
       "      <td>single</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>tue</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>94.027</td>\n",
       "      <td>-38.3</td>\n",
       "      <td>0.886</td>\n",
       "      <td>4991.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40549</th>\n",
       "      <td>58</td>\n",
       "      <td>retired</td>\n",
       "      <td>divorced</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>aug</td>\n",
       "      <td>tue</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>94.027</td>\n",
       "      <td>-38.3</td>\n",
       "      <td>0.886</td>\n",
       "      <td>4991.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40550</th>\n",
       "      <td>34</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>tue</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>94.027</td>\n",
       "      <td>-38.3</td>\n",
       "      <td>0.886</td>\n",
       "      <td>4991.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40551</th>\n",
       "      <td>44</td>\n",
       "      <td>admin.</td>\n",
       "      <td>single</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>aug</td>\n",
       "      <td>tue</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>94.027</td>\n",
       "      <td>-38.3</td>\n",
       "      <td>0.886</td>\n",
       "      <td>4991.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37069 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age          job   marital            education  default housing loan  \\\n",
       "0       56    housemaid   married             basic.4y       no      no   no   \n",
       "1       57     services   married          high.school  unknown      no   no   \n",
       "2       37     services   married          high.school       no     yes   no   \n",
       "3       40       admin.   married             basic.6y       no      no   no   \n",
       "4       56     services   married          high.school       no      no  yes   \n",
       "...    ...          ...       ...                  ...      ...     ...  ...   \n",
       "40544   33  blue-collar   married  professional.course       no     yes   no   \n",
       "40545   31       admin.    single          high.school       no      no   no   \n",
       "40549   58      retired  divorced             basic.4y       no      no   no   \n",
       "40550   34  blue-collar   married             basic.9y       no     yes   no   \n",
       "40551   44       admin.    single          high.school       no     yes   no   \n",
       "\n",
       "         contact month day_of_week  campaign  pdays  previous     poutcome  \\\n",
       "0      telephone   may         mon         1    999         0  nonexistent   \n",
       "1      telephone   may         mon         1    999         0  nonexistent   \n",
       "2      telephone   may         mon         1    999         0  nonexistent   \n",
       "3      telephone   may         mon         1    999         0  nonexistent   \n",
       "4      telephone   may         mon         1    999         0  nonexistent   \n",
       "...          ...   ...         ...       ...    ...       ...          ...   \n",
       "40544   cellular   aug         tue         4    999         0  nonexistent   \n",
       "40545   cellular   aug         tue         1    999         1      failure   \n",
       "40549  telephone   aug         tue         1    999         0  nonexistent   \n",
       "40550   cellular   aug         tue         2    999         0  nonexistent   \n",
       "40551  telephone   aug         tue         1    999         0  nonexistent   \n",
       "\n",
       "       emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  nr.employed  \n",
       "0               1.1          93.994          -36.4      4.857       5191.0  \n",
       "1               1.1          93.994          -36.4      4.857       5191.0  \n",
       "2               1.1          93.994          -36.4      4.857       5191.0  \n",
       "3               1.1          93.994          -36.4      4.857       5191.0  \n",
       "4               1.1          93.994          -36.4      4.857       5191.0  \n",
       "...             ...             ...            ...        ...          ...  \n",
       "40544          -1.7          94.027          -38.3      0.886       4991.6  \n",
       "40545          -1.7          94.027          -38.3      0.886       4991.6  \n",
       "40549          -1.7          94.027          -38.3      0.886       4991.6  \n",
       "40550          -1.7          94.027          -38.3      0.886       4991.6  \n",
       "40551          -1.7          94.027          -38.3      0.886       4991.6  \n",
       "\n",
       "[37069 rows x 19 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_data = PrepareData(path=path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Used to prepare data for modelling"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = prepare_data.load_data(sep=';', cols_to_drop=['duration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = prepare_data.treat_outliers(data, type='isf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40544</th>\n",
       "      <td>33</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>tue</td>\n",
       "      <td>4</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>94.027</td>\n",
       "      <td>-38.3</td>\n",
       "      <td>0.886</td>\n",
       "      <td>4991.6</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40545</th>\n",
       "      <td>31</td>\n",
       "      <td>admin.</td>\n",
       "      <td>single</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>tue</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>94.027</td>\n",
       "      <td>-38.3</td>\n",
       "      <td>0.886</td>\n",
       "      <td>4991.6</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40549</th>\n",
       "      <td>58</td>\n",
       "      <td>retired</td>\n",
       "      <td>divorced</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>aug</td>\n",
       "      <td>tue</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>94.027</td>\n",
       "      <td>-38.3</td>\n",
       "      <td>0.886</td>\n",
       "      <td>4991.6</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40550</th>\n",
       "      <td>34</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>tue</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>94.027</td>\n",
       "      <td>-38.3</td>\n",
       "      <td>0.886</td>\n",
       "      <td>4991.6</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40551</th>\n",
       "      <td>44</td>\n",
       "      <td>admin.</td>\n",
       "      <td>single</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>aug</td>\n",
       "      <td>tue</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>94.027</td>\n",
       "      <td>-38.3</td>\n",
       "      <td>0.886</td>\n",
       "      <td>4991.6</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37069 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age          job   marital            education  default housing loan  \\\n",
       "0       56    housemaid   married             basic.4y       no      no   no   \n",
       "1       57     services   married          high.school  unknown      no   no   \n",
       "2       37     services   married          high.school       no     yes   no   \n",
       "3       40       admin.   married             basic.6y       no      no   no   \n",
       "4       56     services   married          high.school       no      no  yes   \n",
       "...    ...          ...       ...                  ...      ...     ...  ...   \n",
       "40544   33  blue-collar   married  professional.course       no     yes   no   \n",
       "40545   31       admin.    single          high.school       no      no   no   \n",
       "40549   58      retired  divorced             basic.4y       no      no   no   \n",
       "40550   34  blue-collar   married             basic.9y       no     yes   no   \n",
       "40551   44       admin.    single          high.school       no     yes   no   \n",
       "\n",
       "         contact month day_of_week  campaign  pdays  previous     poutcome  \\\n",
       "0      telephone   may         mon         1    999         0  nonexistent   \n",
       "1      telephone   may         mon         1    999         0  nonexistent   \n",
       "2      telephone   may         mon         1    999         0  nonexistent   \n",
       "3      telephone   may         mon         1    999         0  nonexistent   \n",
       "4      telephone   may         mon         1    999         0  nonexistent   \n",
       "...          ...   ...         ...       ...    ...       ...          ...   \n",
       "40544   cellular   aug         tue         4    999         0  nonexistent   \n",
       "40545   cellular   aug         tue         1    999         1      failure   \n",
       "40549  telephone   aug         tue         1    999         0  nonexistent   \n",
       "40550   cellular   aug         tue         2    999         0  nonexistent   \n",
       "40551  telephone   aug         tue         1    999         0  nonexistent   \n",
       "\n",
       "       emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  nr.employed  \\\n",
       "0               1.1          93.994          -36.4      4.857       5191.0   \n",
       "1               1.1          93.994          -36.4      4.857       5191.0   \n",
       "2               1.1          93.994          -36.4      4.857       5191.0   \n",
       "3               1.1          93.994          -36.4      4.857       5191.0   \n",
       "4               1.1          93.994          -36.4      4.857       5191.0   \n",
       "...             ...             ...            ...        ...          ...   \n",
       "40544          -1.7          94.027          -38.3      0.886       4991.6   \n",
       "40545          -1.7          94.027          -38.3      0.886       4991.6   \n",
       "40549          -1.7          94.027          -38.3      0.886       4991.6   \n",
       "40550          -1.7          94.027          -38.3      0.886       4991.6   \n",
       "40551          -1.7          94.027          -38.3      0.886       4991.6   \n",
       "\n",
       "         y  \n",
       "0       no  \n",
       "1       no  \n",
       "2       no  \n",
       "3       no  \n",
       "4       no  \n",
       "...    ...  \n",
       "40544  yes  \n",
       "40545   no  \n",
       "40549   no  \n",
       "40550   no  \n",
       "40551   no  \n",
       "\n",
       "[37069 rows x 20 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/.local/lib/python3.6/site-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "data = prepare_data.encode(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.28571429, -0.5       ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.35714286, -0.5       ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.07142857, -0.5       ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.28571429, -0.5       ,  0.        , ...,  0.        ,\n",
       "        -1.        ,  1.        ],\n",
       "       [-0.42857143, -0.5       ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.28571429,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_data.scale_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Module Plot.py codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "import os\n",
    "\n",
    "def plot_univariate (data, x=None, y=None, color='r',save=False,\n",
    "                title='New Chart', chart_type='hist', xlabel='', ylabel='',\n",
    "                    save_to=os.getcwd(), log_normalise=False):\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Make a univariate plot of any of these selcted types:\n",
    "    \n",
    "    1. bar - barchart\n",
    "    \n",
    "    2. hist - Histogram\n",
    "    \n",
    "    3. pie - Piechart\n",
    "    \n",
    "    4. count - Countplot\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    plt.subplots(figsize=(10,7))\n",
    "    plt.title(title, fontsize=18)\n",
    "    plt.xlabel(xlabel, fontsize=15)\n",
    "    plt.ylabel(ylabel, fontsize=15)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    \n",
    "    \n",
    "    if chart_type == 'hist':\n",
    "        if log_normalise:\n",
    "            data = np.log(data)\n",
    "        plot = sns.distplot(a=data, color=color)\n",
    "        if save:\n",
    "            plt.savefig(fname=save_to+f'/{title}.png', format='png')\n",
    "        \n",
    "    return plot\n",
    "\n",
    "def plot_bivariate(data, x=None, y=None, hue=None, \n",
    "                  color='r',save=False,\n",
    "                title='New Chart', chart_type='hist',\n",
    "                   xlabel='', ylabel='',\n",
    "                    save_to=os.getcwd(), img_name = \" \", \n",
    "                   palette={'use':False, \"size\":1}, log_normalise=False,\n",
    "                  kind_joint_plot = 'scatter', kind_pair_plot=\"scatter\", figsize=(10,7)):\n",
    "    \n",
    "    \"\"\"\n",
    "    Make a bivariate plot of any of the selcted types:\n",
    "    \n",
    "    1. bar - barchart\n",
    "    \n",
    "    2. scatter  - scatter plot\n",
    "    \n",
    "    3. cat  - catplot\n",
    "    \n",
    "    4. count - countplot\n",
    "    \n",
    "    5 joint - jointplot \n",
    "    \n",
    "    6  pair - pairplot\n",
    "    \n",
    "    7  corr - corr_plot\n",
    "    \n",
    "    When calling joint_plot:\n",
    "        \n",
    "        kind_joint_plot is default to `scatter`\n",
    "        other types include \"reg\", \"reside\", \"kde\", \"hex\"\n",
    "        \n",
    "    When calling pair_plot:\n",
    "        \n",
    "        kind_pair_plot is default to `scatter`\n",
    "        other types include 'reg'\n",
    "    \"\"\"\n",
    "    def plt_tweaks():\n",
    "        plt.subplots(figsize= figsize)\n",
    "        plt.title(title, fontsize=18)\n",
    "        plt.xlabel(xlabel, fontsize=15)\n",
    "        plt.ylabel(ylabel, fontsize=15)\n",
    "        plt.xticks(fontsize=12)\n",
    "        plt.yticks(fontsize=12)\n",
    "    \n",
    "    \n",
    "    # define helper functions\n",
    "    \n",
    "    def use_palette():\n",
    "        palettes = []\n",
    "#        palette_to_use=[]\n",
    "        if palette['use'] == True:\n",
    "            palette_to_use = [palettes[i] for i in range(palette['size'])]\n",
    "            \n",
    "            return palette_to_use\n",
    "\n",
    "    def log_norm():\n",
    "        if log_normalise and y != None:\n",
    "            y = np.log(y)\n",
    "        elif log_normalise and y == None:\n",
    "            data = np.log(data)\n",
    "            \n",
    "    def save_image():\n",
    "        if save:\n",
    "            if img_name != \" \":\n",
    "                plt.savefig(fname=save_to+\"/\"+img_name+'.png', format='png')\n",
    "            else:\n",
    "                plt.savefig(fname=save_to+f'/{title}.png', format='png')\n",
    "                \n",
    "        \n",
    "    # make plots\n",
    "    \n",
    "    if chart_type == \"joint\":\n",
    "        log_norm()\n",
    "        plot = sns.jointplot(x=x, y=y, data=data,\n",
    "                            height=6, ratio=5, space=0.2, kind=kind_joint_plot)\n",
    "        \n",
    "        save_image()\n",
    "        \n",
    "    if chart_type == \"pair\":\n",
    "       # try:\n",
    "        log_norm()\n",
    "        if palette['use'] == True:\n",
    "            palette_to_use = use_palette()\n",
    "            plot = sns.pairplot(data, palette=palette_to_use, \n",
    "                            kind= kind_pair_plot,height=3, aspect=1, hue=hue)\n",
    "        else:\n",
    "             plot = sns.pairplot(data, \n",
    "                            kind= kind_pair_plot,height=2.5, aspect=1, hue=hue, )\n",
    "        save_image()\n",
    "        \n",
    "    if chart_type  == \"corr\":\n",
    "        plt_tweaks()\n",
    "        corr_data = data.corr()\n",
    "        corr_plot = sns.heatmap(corr_data,annot=True, fmt='.2g', center=0) \n",
    "        \n",
    "    return plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Module Model.py Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE, _random_over_sampler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from imblearn.pipeline import Pipeline as ImbPipe\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GridSearchCV\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, cross_validate\n",
    "\n",
    "def plot_pca_components(data):\n",
    "    pca = PCA().fit(data)\n",
    "    plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "    plt.xlabel('number of components')\n",
    "    plt.ylabel('cumulative explained variance');\n",
    "    \n",
    "def check_imbalance(data,label='', x=0.7, y=30000):\n",
    "    plt.subplots(figsize=(10,8))\n",
    "    data[label].value_counts().plot(kind='bar')\n",
    "    text = f'Class Imbalance Count:\\n\\n{data[label].value_counts().to_dict()}'\n",
    "    plt.text(x=x, y=y, s = text ,  fontsize=15)\n",
    "    \n",
    "def encode (data):\n",
    "    ohe = OneHotEncoder(sparse=False, handle_unknown='ignore', )\n",
    "    to_encode = data.select_dtypes(exclude='number')\n",
    "    if data.shape[1] > 1:\n",
    "        #ohe = MultiLabelBinarizer()\n",
    "        data.drop(to_encode.columns.tolist(), axis=1, inplace = True)\n",
    "        features_cat_encode = pd.DataFrame(ohe.fit_transform(to_encode))\n",
    "        data = data.merge(features_cat_encode, left_index=True, right_index=True)\n",
    "        #print(ohe.classes_) \n",
    "    else:\n",
    "        data = pd.DataFrame(ohe.fit_transform(to_encode))\n",
    "        print(ohe.categories_) \n",
    "    return data \n",
    "\n",
    " \n",
    "\n",
    "def x_y_split(data, x=None, y=None, type_=\"single\", test_size=.10):\n",
    "    \n",
    "    \"\"\"\n",
    "    Single type divides into just x and y\n",
    "    Double type divides into train and test for each of x and y\n",
    "    \"\"\"\n",
    "    \n",
    "    X, y = data.drop(columns=y, axis=1), data[y]\n",
    "    \n",
    "    if type_ == \"single\":\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    if type == \"double\":\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                               test_size=test_size, random_state=123)\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    \n",
    "    \n",
    "def model_pipeline(X_train=None, y_train=None, X_test=None, pca=PCA(), \n",
    "                   cv=StratifiedKFold(), imb_sample=SMOTE(random_state=123),\n",
    "                  model=LogisticRegressionCV()):\n",
    "    \n",
    "    \"\"\"\n",
    "    Trains a model for an imbalanced class using the specified estimator\n",
    "    The training is done in K-folds or its nuances as specified folds \n",
    "    applying the specified sampling strategy\n",
    "    \"\"\"\n",
    "    \n",
    "    model = ImbPipe([('imb_sample', imb_sample), ('pca', pca), ('model', model)])\n",
    "    model.fit(X_train, y_train) \n",
    "    y_hat = model.predict(X_test) \n",
    "    return model, y_hat\n",
    "    \n",
    "    \n",
    "def gridSearch(model,hyper_params={},cv=StratifiedKFold(), x_train=None, y_train=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Performs GridSeach of the best hyperparmaters for the passed model\n",
    "    \"\"\"\n",
    "    \n",
    "    search = GridSearchCV(model=model, param_grid = hyper_params, n_jobs=-1, cv=cv)\n",
    "    search.fit(X=x_train, y=y_train)\n",
    "    print(\"Best parameter (CV score=%0.3f):\\n\" % search.best_score_)\n",
    "    print(search.best_params_)\n",
    "    print(search.score) \n",
    "    return search\n",
    "\n",
    "\n",
    "def plot_grid_search(search_obj, pca_obj, X_train):\n",
    "    \n",
    "    \"\"\"\n",
    "    Prints the best (optimised) hyperparmatersfor the grid search object\n",
    "    and plots the optimised pca components\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Best parameter (CV score=%0.3f):\\n\" % search.best_score_)\n",
    "    print(\"Best Params:\",search.best_params_)\n",
    "    pca.fit(X_train_scaled)\n",
    "\n",
    "    fig, (ax0, ax1) = plt.subplots(nrows=2, sharex=True, figsize=(8, 8))\n",
    "    ax0.plot(np.arange(1, pca.n_components_ + 1),\n",
    "             pca.explained_variance_ratio_, '+', linewidth=2)\n",
    "    ax0.set_ylabel('PCA explained variance ratio')\n",
    "\n",
    "    ax0.axvline(search.best_estimator_.named_steps['pca'].n_components,\n",
    "                linestyle=':', label='n_components chosen')\n",
    "    ax0.legend(prop=dict(size=12))\n",
    "\n",
    "    # For each number of components, find the best classifier results\n",
    "    results = pd.DataFrame(search.cv_results_)\n",
    "    components_col = 'param_pca__n_components'\n",
    "    best_clfs = results.groupby(components_col).apply(\n",
    "        lambda g: g.nlargest(1, 'mean_test_score'))\n",
    "\n",
    "    best_clfs.plot(x=components_col, y='mean_test_score', yerr='std_test_score',\n",
    "                   legend=False, ax=ax1)\n",
    "    ax1.set_ylabel('Classification accuracy (val)')\n",
    "    ax1.set_xlabel('n_components')\n",
    "\n",
    "    plt.xlim(-1, 70)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show() \n",
    "    \n",
    "\n",
    "class metrics ():\n",
    "    \n",
    "    def __init__(self, y_test, y_hat):\n",
    "        pass\n",
    "        self.y_test = y_test\n",
    "        self.y_hat =  y_hat\n",
    "        \n",
    "    \n",
    "    def class_report(self):\n",
    "        \n",
    "        full_report = classification_report(self.y_test, self.y_hat)\n",
    "        \n",
    "        print(full_report)\n",
    "        \n",
    "    def conf_matrix(self):\n",
    "        \n",
    "        conf_matrix = confusion_matrix(self.y_test, self.y_hat)\n",
    "        \n",
    "        conf_matrix_df = pd.DataFrame(conf_matrix, columns=['Actual_+ve', 'Actual_-ve'],\n",
    "                               index=['predicted_+ve', 'predicted_-ve'])\n",
    "        \n",
    "        return conf_matrix_df\n",
    "    \n",
    "    def accuracy_score(self):\n",
    "        return  accuracy_score(self.y_test, self.y_hat)\n",
    "    \n",
    "    def classification_error(self):\n",
    "        \n",
    "        return 1 - accuracy_score() \n",
    "        \n",
    "    def specif_sensitiv(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        Sensitivity: When the actual value is positive, how often is the prediction correct?\n",
    "        \n",
    "        Specificity: When the actual value is negative, how often is the prediction correct?\n",
    "        \"\"\"\n",
    "        \n",
    "        conf_matrix = confusion_matrix(self.y_test, self.y_hat)\n",
    "        \n",
    "        TP = conf_matrix[1, 1]\n",
    "        TN = conf_matrix[0, 0]\n",
    "        FP = conf_matrix[0, 1]\n",
    "        FN = conf_matrix[1, 0]\n",
    "        \n",
    "        sensitivity = TP / float(FN + TP)\n",
    "        specificity = TN / (TN + FP)\n",
    "        \n",
    "        sensitiv_specific_table = pd.DataFrame([[sensitivity, specificity]],\n",
    "                                               columns=['sensitivity', 'specificity'])\n",
    "        \n",
    "        return sensitiv_specific_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV()"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogisticRegressionCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_termsheet_pred_model",
   "language": "python",
   "name": "venv_termsheet_pred_model"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
