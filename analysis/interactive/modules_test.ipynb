{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "from pandas.api.types import is_numeric_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "path= '../../datasets/main_data/bank-additional-full.csv'\n",
    "full_bank = pd.read_csv(path, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Module Data.py codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile data.py\n",
    "# %%writefile ../scripts/data.py\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as  np\n",
    "import pandas as pd\n",
    "import pandas\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import os\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, MultiLabelBinarizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "def load_data(path=\"\", sep=\",\", cols_to_drop=[]):\n",
    "            \n",
    "        try :\n",
    "            data = pd.read_csv(path, sep)\n",
    "            \n",
    "            if len(cols_to_drop) > 0:\n",
    "                for col in cols_to_drop:\n",
    "                    data.drop(col, axis=1, inplace=True)\n",
    "\n",
    "            return data \n",
    "        \n",
    "        except:\n",
    "            \n",
    "            \"No data path was passed upon inastantiation of object\"\n",
    "    \n",
    "\n",
    "\n",
    "# define class Preprocess to preprocess data\n",
    "# class Preprocess inherits from BaseEstimator & TransformerMixin\n",
    "# the idea behind the Preprocess class is to preprocess our data ready for modelling\n",
    "\n",
    "class Preprocessor(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __repr__(self):\n",
    "        \n",
    "        return \"Used to prepare data for modelling\"\n",
    "    \n",
    "    def  __init__(self):\n",
    "        \n",
    "        pass\n",
    "        \n",
    "#         self.path = path\n",
    "#         self.cols_to_drop = cols_to_drop \n",
    "#         self.sep = sep \n",
    "        \n",
    "        \n",
    "    \n",
    "    def fit(self, data):\n",
    "        \n",
    "        assert(type(data) is pandas.core.frame.DataFrame), \"data must be of type pandas.DataFrame\"\n",
    "        self.data = data\n",
    "        return self\n",
    "        \n",
    "\n",
    "\n",
    "    def check_outliers(self, show_plot=False, save_img=os.getcwd()+'/outliers.png'):\n",
    "            \n",
    "        \"\"\"\n",
    "        This functions checks for columns with outlers using the IQR method\n",
    "\n",
    "        It accespts as argmuent a dataset. \n",
    "        show_plot can be set to True to output pairplots of outlier columns    \n",
    "        \"\"\"\n",
    "\n",
    "        self.outliers = [] \n",
    "        Q1 = self.data.quantile(0.25)  \n",
    "        Q3 = self.data.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        num_data = self.data.select_dtypes(include='number')\n",
    "        result = dict ((((num_data < (Q1 - 1.5 * IQR)) | (num_data > (Q3 + 1.5 * IQR)))==True).any())\n",
    "        #data[(data[col] >= high)|(data[col] <= low)].index\n",
    "        index = self.data[(num_data < Q1 - 1.5 * IQR) | (num_data > Q3 + 1.5 * IQR)].index\n",
    "        for k,v in result.items():\n",
    "            if v == True:  \n",
    "                self.outliers.append(k)\n",
    "        if show_plot:\n",
    "            self.outlier_pair_plot = sns.pairplot(self.data[self.outliers]);\n",
    "            print(f'{result},\\n\\n Visualization of outlier columns')\n",
    "            plt.savefig(fname=save_img, format='png')\n",
    "            return  self.outlier_pair_plot\n",
    "        else:\n",
    "            return self.data.loc[index, outliers] \n",
    "        \n",
    "        \n",
    "    def treat_outliers(self, type_='median_replace'):\n",
    "            \n",
    "        \"\"\"\n",
    "        This treat outliers using any ofthses 3 methods as specified by user\n",
    "\n",
    "            1. median_replace -  median replacement\n",
    "\n",
    "            2. quant_floor - quantile flooring\n",
    "\n",
    "            3. trim - trimming \n",
    "\n",
    "            4. log_transform - log transformations\n",
    "\n",
    "        The methods are some of the commont statistical methods in treating outler\n",
    "        columns\n",
    "\n",
    "        By default treatment type is set to median replacement\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if type_ == \"median_replace\":\n",
    "\n",
    "            for col in self.data.columns.tolist():\n",
    "                if is_numeric_dtype(self.data[col]):\n",
    "                    median = (self.data[col].quantile(0.50))\n",
    "                    print(median)\n",
    "                    q1 = self.data[col].quantile(0.25)\n",
    "                    q3 = self.data[col].quantile(0.75)\n",
    "                    iqr = q3 - q1\n",
    "                    high = int(q3 + 1.5 * iqr) \n",
    "                    low = int(q1 - 1.5 * iqr)\n",
    "                    print(high, low, iqr)\n",
    "                    print(col)\n",
    "                    self.data[col] = np.where(self.data[col] > high, median, self.data[col])\n",
    "                    self.data[col] = np.where(self.data[col] > high, median, self.data[col])        \n",
    "\n",
    "        if type_ == \"quant_floor\":\n",
    "\n",
    "            for col in self.data.columns.tolist():\n",
    "                if is_numeric_dtype(data[col]):\n",
    "                    q_10 = self.data[col].quantile(0.5)\n",
    "                    q_90 = self.data[col].quantile(0.95)\n",
    "                    self.data[col] =  self.data[col] = np.where(self.data[col] < q_10, q_10 , self.data[col])\n",
    "                    self.data[col] =  self.data[col] = np.where(self.data[col] > q_90, q_90 , self.data[col])\n",
    "\n",
    "        if type_ == \"trim\": \n",
    "\n",
    "            for col in self.data.columns.tolist():\n",
    "                low = .05\n",
    "                high = .95\n",
    "                quant_df = self.data.quantile([low, high])\n",
    "                for name in list(self.data.columns):\n",
    "                    if is_numeric_dtype(self.data[name]):\n",
    "                        self.data = self.data[(self.data[name] >= quant_df.loc[low, name]) \n",
    "                            & (self.data[name] <= quant_df.loc[high, name])]\n",
    "\n",
    "        if type_ == \"log_transform\":  \n",
    "            for col in self.data.columns.tolist():\n",
    "                if is_numeric_dtype(self.data[col]):\n",
    "                    self.data[col] = self.data[col].map(lambda i: np.log(i) if i > 0 else 0)\n",
    "\n",
    "        if type_ == \"isf\":\n",
    "            iso = IsolationForest(contamination=0.1)\n",
    "            yhat = iso.fit_predict(self.data.select_dtypes(exclude='object'))\n",
    "            #select all rows that are not outliers\n",
    "            mask = yhat != -1 \n",
    "            self.data = self.data[mask]\n",
    "\n",
    "\n",
    "        return self.data \n",
    "    \n",
    "    \n",
    "    def map_col_values(self, col_name=\"\", values_dict={}):\n",
    "\n",
    "        self.data[col_name] = self.data[col_name].map(values_dict)\n",
    "\n",
    "        return self.data\n",
    "    \n",
    "    \n",
    "    def split_data_single(self, target_cols=[]):\n",
    "            \n",
    "        self.features = self.data.drop(columns=target_cols, axis=1) \n",
    "\n",
    "        self.target   = pd.DataFrame(self.data[target_cols])\n",
    "\n",
    "        return self.features, self.target\n",
    "    \n",
    "    \n",
    "    def encode (self, data_obj=None): \n",
    "        \n",
    "        if data_obj is not None:\n",
    "        \n",
    "            ohe = OneHotEncoder(sparse=False, handle_unknown='ignore', )\n",
    "            to_encode = self.data.select_dtypes(exclude='number')\n",
    "            if self.data.shape[1] > 1:\n",
    "                #ohe = MultiLabelBinarizer()\n",
    "                self.data.drop(to_encode.columns.tolist(), axis=1, inplace = True)\n",
    "                features_cat_encode = pd.DataFrame(ohe.fit_transform(to_encode))\n",
    "                self.data = self.data.merge(features_cat_encode, left_index=True, right_index=True)\n",
    "               # print(ohe.classes_) \n",
    "            else:\n",
    "                self.data = pd.DataFrame(ohe.fit_transform(to_encode))\n",
    "                print(ohe.categories_) \n",
    "            return self.data\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            self.data_obj = data_obj\n",
    "            \n",
    "            ohe = OneHotEncoder(sparse=False, handle_unknown='ignore', )\n",
    "            to_encode = self.data_obj.select_dtypes(exclude='number')\n",
    "            if self.data_obj.shape[1] > 1:\n",
    "                #ohe = MultiLabelBinarizer()\n",
    "                self.data_obj.drop(to_encode.columns.tolist(), axis=1, inplace = True)\n",
    "                features_cat_encode = pd.DataFrame(ohe.fit_transform(to_encode))\n",
    "                self.data_obj = self.data_obj.merge(features_cat_encode, left_index=True, right_index=True)\n",
    "               # print(ohe.classes_) \n",
    "            else:\n",
    "                self.data_obj = pd.DataFrame(ohe.fit_transform(to_encode))\n",
    "                print(ohe.categories_) \n",
    "            return self.data_obj\n",
    "            \n",
    "    \n",
    "    def split_data_double(self, features, target, test_size=.10):\n",
    "        \n",
    "        if features.shape[0] != target.shape[0]:\n",
    "            raise Exception(\"Wrong, you are trying to pass unequal shapes\\n\\\n",
    "            Shapes of dataframes must be equal\\n\\\n",
    "            Try target = target.iloc[0:features.shape[0]]\")\n",
    "        \n",
    "        self.features = features\n",
    "        self.target = target\n",
    "        \n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.features, self.target,\n",
    "                                               test_size= test_size, random_state=24)\n",
    "        \n",
    "        return self.X_train, self.X_test, self.y_train, self.y_test\n",
    "\n",
    "\n",
    "    def scale_data(self, scaler=RobustScaler()):\n",
    "    \n",
    "        \"\"\"\n",
    "        Specify scaler type, scaler type must have fit_transform as a method\n",
    "\n",
    "        \"\"\"\n",
    "        self.data_scaled = scaler.fit_transform(self.data)\n",
    "        \n",
    "        return self.data_scaled\n",
    "    \n",
    "    \n",
    "    def transform(self, data):\n",
    "        \n",
    "        #self.X = X\n",
    "                \n",
    "        self.data = self.treat_outliers(type_=\"isf\")\n",
    "        \n",
    "        self.data = self.map_col_values(col_name=\"y\", values_dict={\"no\":0, \"yes\":1})\n",
    "        \n",
    "        self.features, self.target = self.split_data_single(target_cols=[\"y\"])\n",
    "                \n",
    "        self.features = self.encode(self.features)\n",
    "        \n",
    "        self.target = self.target.iloc[0:self.features.shape[0]]\n",
    "        \n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = self.split_data_double(\n",
    "            self.features, self.target, test_size=.10)\n",
    "        \n",
    "        scaler=RobustScaler()\n",
    "            \n",
    "        self.X = scaler.fit_transform(self.X_train)\n",
    "        \n",
    "        return self.X\n",
    "    \n",
    "    \n",
    "    def transform_2(self):\n",
    "        \n",
    "        #self.X = X\n",
    "                \n",
    "        self.data = self.treat_outliers(type_=\"isf\")\n",
    "        \n",
    "        self.data = self.map_col_values(col_name=\"y\", values_dict={\"no\":0, \"yes\":1})\n",
    "        \n",
    "        self.features, self.target = self.split_data_single(target_cols=[\"y\"])\n",
    "                \n",
    "        self.features = self.encode(self.features)\n",
    "        \n",
    "        self.target = self.target.iloc[0:self.features.shape[0]]\n",
    "        \n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = self.split_data_double(\n",
    "            self.features, self.target, test_size=.10)\n",
    "        \n",
    "        scaler=RobustScaler()\n",
    "            \n",
    "        self.X = scaler.fit_transform(self.X_train)\n",
    "        \n",
    "        return self.X\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data.py module codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.estimator_checks import check_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Preprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(path, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Used to prepare data for modelling"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41183</th>\n",
       "      <td>73</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41184</th>\n",
       "      <td>46</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41185</th>\n",
       "      <td>56</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41186</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41187</th>\n",
       "      <td>74</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>professional.course</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>fri</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>94.767</td>\n",
       "      <td>-50.8</td>\n",
       "      <td>1.028</td>\n",
       "      <td>4963.6</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41188 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age          job  marital            education  default housing loan  \\\n",
       "0       56    housemaid  married             basic.4y       no      no   no   \n",
       "1       57     services  married          high.school  unknown      no   no   \n",
       "2       37     services  married          high.school       no     yes   no   \n",
       "3       40       admin.  married             basic.6y       no      no   no   \n",
       "4       56     services  married          high.school       no      no  yes   \n",
       "...    ...          ...      ...                  ...      ...     ...  ...   \n",
       "41183   73      retired  married  professional.course       no     yes   no   \n",
       "41184   46  blue-collar  married  professional.course       no      no   no   \n",
       "41185   56      retired  married    university.degree       no     yes   no   \n",
       "41186   44   technician  married  professional.course       no      no   no   \n",
       "41187   74      retired  married  professional.course       no     yes   no   \n",
       "\n",
       "         contact month day_of_week  ...  campaign  pdays  previous  \\\n",
       "0      telephone   may         mon  ...         1    999         0   \n",
       "1      telephone   may         mon  ...         1    999         0   \n",
       "2      telephone   may         mon  ...         1    999         0   \n",
       "3      telephone   may         mon  ...         1    999         0   \n",
       "4      telephone   may         mon  ...         1    999         0   \n",
       "...          ...   ...         ...  ...       ...    ...       ...   \n",
       "41183   cellular   nov         fri  ...         1    999         0   \n",
       "41184   cellular   nov         fri  ...         1    999         0   \n",
       "41185   cellular   nov         fri  ...         2    999         0   \n",
       "41186   cellular   nov         fri  ...         1    999         0   \n",
       "41187   cellular   nov         fri  ...         3    999         1   \n",
       "\n",
       "          poutcome emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  \\\n",
       "0      nonexistent          1.1          93.994          -36.4      4.857   \n",
       "1      nonexistent          1.1          93.994          -36.4      4.857   \n",
       "2      nonexistent          1.1          93.994          -36.4      4.857   \n",
       "3      nonexistent          1.1          93.994          -36.4      4.857   \n",
       "4      nonexistent          1.1          93.994          -36.4      4.857   \n",
       "...            ...          ...             ...            ...        ...   \n",
       "41183  nonexistent         -1.1          94.767          -50.8      1.028   \n",
       "41184  nonexistent         -1.1          94.767          -50.8      1.028   \n",
       "41185  nonexistent         -1.1          94.767          -50.8      1.028   \n",
       "41186  nonexistent         -1.1          94.767          -50.8      1.028   \n",
       "41187      failure         -1.1          94.767          -50.8      1.028   \n",
       "\n",
       "       nr.employed    y  \n",
       "0           5191.0   no  \n",
       "1           5191.0   no  \n",
       "2           5191.0   no  \n",
       "3           5191.0   no  \n",
       "4           5191.0   no  \n",
       "...            ...  ...  \n",
       "41183       4963.6  yes  \n",
       "41184       4963.6   no  \n",
       "41185       4963.6   no  \n",
       "41186       4963.6  yes  \n",
       "41187       4963.6   no  \n",
       "\n",
       "[41188 rows x 21 columns]"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "2   37   services  married  high.school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4   56   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
       "0   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "1   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "2   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "3   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "4   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0          93.994          -36.4      4.857       5191.0  no  \n",
       "1          93.994          -36.4      4.857       5191.0  no  \n",
       "2          93.994          -36.4      4.857       5191.0  no  \n",
       "3          93.994          -36.4      4.857       5191.0  no  \n",
       "4          93.994          -36.4      4.857       5191.0  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/.local/lib/python3.6/site-packages/ipykernel_launcher.py:167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/patrick/.local/lib/python3.6/site-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.21428571,  2.89099526, -0.5       , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.07142857,  0.30805687,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.42857143,  0.00473934,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 1.42857143,  1.67772512, -0.5       , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.28571429, -0.53554502,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.57142857, -0.14218009,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "fu = FeatureUnion([(\"process\", Preprocessor()), #(\"pca\", PCA(n_components=45))\n",
    "                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/.local/lib/python3.6/site-packages/ipykernel_launcher.py:167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/patrick/.local/lib/python3.6/site-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.35714286,  0.9       ,  1.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.14285714,  0.35714286,  2.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.57142857, -0.3       , -0.5       , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [-0.42857143, -0.6047619 ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.85714286, -0.32380952,  0.5       , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.57142857, -0.14285714,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fu.fit_transform(X=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_data = PrepareData(path=path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = prepare_data.load_data(sep=';', cols_to_drop=['duration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = prepare_data.treat_outliers(data, type='isf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = prepare_data.map_col_values(data, 'y', values_dict={'no':0, 'yes':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = split_data_single(data, target_cols=['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = prepare_data.encode(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = b.iloc[0:a.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_data.split_data_double(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= prepare_data.scale_data(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "b= prepare_data.scale_data(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Module plot.py codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "import os\n",
    "\n",
    "def plot_univariate (data, x=None, y=None, color='r',save=False,\n",
    "                title='New Chart', chart_type='hist', xlabel='', ylabel='',\n",
    "                    save_to=os.getcwd(), log_normalise=False):\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Make a univariate plot of any of these selcted types:\n",
    "    \n",
    "    1. bar - barchart\n",
    "    \n",
    "    2. hist - Histogram\n",
    "    \n",
    "    3. pie - Piechart\n",
    "    \n",
    "    4. count - Countplot\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    plt.subplots(figsize=(10,7))\n",
    "    plt.title(title, fontsize=18)\n",
    "    plt.xlabel(xlabel, fontsize=15)\n",
    "    plt.ylabel(ylabel, fontsize=15)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    \n",
    "    \n",
    "    if chart_type == 'hist':\n",
    "        if log_normalise:\n",
    "            data = np.log(data)\n",
    "        plot = sns.distplot(a=data, color=color)\n",
    "        if save:\n",
    "            plt.savefig(fname=save_to+f'/{title}.png', format='png')\n",
    "        \n",
    "    return plot\n",
    "\n",
    "def plot_bivariate(data, x=None, y=None, hue=None, \n",
    "                  color='r',save=False,\n",
    "                title='New Chart', chart_type='hist',\n",
    "                   xlabel='', ylabel='',\n",
    "                    save_to=os.getcwd(), img_name = \" \", \n",
    "                   palette={'use':False, \"size\":1}, log_normalise=False,\n",
    "                  kind_joint_plot = 'scatter', kind_pair_plot=\"scatter\", figsize=(10,7)):\n",
    "    \n",
    "    \"\"\"\n",
    "    Make a bivariate plot of any of the selcted types:\n",
    "    \n",
    "    1. bar - barchart\n",
    "    \n",
    "    2. scatter  - scatter plot\n",
    "    \n",
    "    3. cat  - catplot\n",
    "    \n",
    "    4. count - countplot\n",
    "    \n",
    "    5 joint - jointplot \n",
    "    \n",
    "    6  pair - pairplot\n",
    "    \n",
    "    7  corr - corr_plot\n",
    "    \n",
    "    When calling joint_plot:\n",
    "        \n",
    "        kind_joint_plot is default to `scatter`\n",
    "        other types include \"reg\", \"reside\", \"kde\", \"hex\"\n",
    "        \n",
    "    When calling pair_plot:\n",
    "        \n",
    "        kind_pair_plot is default to `scatter`\n",
    "        other types include 'reg'\n",
    "    \"\"\"\n",
    "    def plt_tweaks():\n",
    "        plt.subplots(figsize= figsize)\n",
    "        plt.title(title, fontsize=18)\n",
    "        plt.xlabel(xlabel, fontsize=15)\n",
    "        plt.ylabel(ylabel, fontsize=15)\n",
    "        plt.xticks(fontsize=12)\n",
    "        plt.yticks(fontsize=12)\n",
    "    \n",
    "    \n",
    "    # define helper functions\n",
    "    \n",
    "    def use_palette():\n",
    "        palettes = []\n",
    "#        palette_to_use=[]\n",
    "        if palette['use'] == True:\n",
    "            palette_to_use = [palettes[i] for i in range(palette['size'])]\n",
    "            \n",
    "            return palette_to_use\n",
    "\n",
    "    def log_norm():\n",
    "        if log_normalise and y != None:\n",
    "            y = np.log(y)\n",
    "        elif log_normalise and y == None:\n",
    "            data = np.log(data)\n",
    "            \n",
    "    def save_image():\n",
    "        if save:\n",
    "            if img_name != \" \":\n",
    "                plt.savefig(fname=save_to+\"/\"+img_name+'.png', format='png')\n",
    "            else:\n",
    "                plt.savefig(fname=save_to+f'/{title}.png', format='png')\n",
    "                \n",
    "        \n",
    "    # make plots\n",
    "    \n",
    "    if chart_type == \"joint\":\n",
    "        log_norm()\n",
    "        plot = sns.jointplot(x=x, y=y, data=data,\n",
    "                            height=6, ratio=5, space=0.2, kind=kind_joint_plot)\n",
    "        \n",
    "        save_image()\n",
    "        \n",
    "    if chart_type == \"pair\":\n",
    "       # try:\n",
    "        log_norm()\n",
    "        if palette['use'] == True:\n",
    "            palette_to_use = use_palette()\n",
    "            plot = sns.pairplot(data, palette=palette_to_use, \n",
    "                            kind= kind_pair_plot,height=3, aspect=1, hue=hue)\n",
    "        else:\n",
    "             plot = sns.pairplot(data, \n",
    "                            kind= kind_pair_plot,height=2.5, aspect=1, hue=hue, )\n",
    "        save_image()\n",
    "        \n",
    "    if chart_type  == \"corr\":\n",
    "        plt_tweaks()\n",
    "        corr_data = data.corr()\n",
    "        corr_plot = sns.heatmap(corr_data,annot=True, fmt='.2g', center=0) \n",
    "        \n",
    "    return plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing plot.py module codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Module Model.py Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE, _random_over_sampler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from imblearn.pipeline import Pipeline as ImbPipe\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GridSearchCV\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, cross_validate\n",
    "\n",
    "def plot_pca_components(data):\n",
    "    pca = PCA().fit(data)\n",
    "    plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "    plt.xlabel('number of components')\n",
    "    plt.ylabel('cumulative explained variance');\n",
    "    \n",
    "def check_imbalance(data,label='', x=0.7, y=30000):\n",
    "    plt.subplots(figsize=(10,8))\n",
    "    data[label].value_counts().plot(kind='bar')\n",
    "    text = f'Class Imbalance Count:\\n\\n{data[label].value_counts().to_dict()}'\n",
    "    plt.text(x=x, y=y, s = text ,  fontsize=15)\n",
    "    \n",
    "def encode (data):\n",
    "    ohe = OneHotEncoder(sparse=False, handle_unknown='ignore', )\n",
    "    to_encode = data.select_dtypes(exclude='number')\n",
    "    if data.shape[1] > 1:\n",
    "        #ohe = MultiLabelBinarizer()\n",
    "        data.drop(to_encode.columns.tolist(), axis=1, inplace = True)\n",
    "        features_cat_encode = pd.DataFrame(ohe.fit_transform(to_encode))\n",
    "        data = data.merge(features_cat_encode, left_index=True, right_index=True)\n",
    "        #print(ohe.classes_) \n",
    "    else:\n",
    "        data = pd.DataFrame(ohe.fit_transform(to_encode))\n",
    "        print(ohe.categories_) \n",
    "    return data \n",
    "\n",
    " \n",
    "\n",
    "def x_y_split(data, x=None, y=None, type_=\"single\", test_size=.10):\n",
    "    \n",
    "    \"\"\"\n",
    "    Single type divides into just x and y\n",
    "    Double type divides into train and test for each of x and y\n",
    "    \"\"\"\n",
    "    \n",
    "    X, y = data.drop(columns=y, axis=1), data[y]\n",
    "    \n",
    "    if type_ == \"single\":\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    if type == \"double\":\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                               test_size=test_size, random_state=123)\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    \n",
    "    \n",
    "def model_pipeline(X_train=None, y_train=None, X_test=None, pca=PCA(), \n",
    "                   cv=StratifiedKFold(), imb_sample=SMOTE(random_state=123),\n",
    "                  model=LogisticRegressionCV()):\n",
    "    \n",
    "    \"\"\"\n",
    "    Trains a model for an imbalanced class using the specified estimator\n",
    "    The training is done in K-folds or its nuances as specified folds \n",
    "    applying the specified sampling strategy\n",
    "    \"\"\"\n",
    "    \n",
    "    model = ImbPipe([('imb_sample', imb_sample), ('pca', pca), ('model', model)])\n",
    "    model.fit(X_train, y_train) \n",
    "    y_hat = model.predict(X_test) \n",
    "    return model, y_hat\n",
    "    \n",
    "    \n",
    "def gridSearch(model,hyper_params={},cv=StratifiedKFold(), x_train=None, y_train=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Performs GridSeach of the best hyperparmaters for the passed model\n",
    "    \"\"\"\n",
    "    \n",
    "    search = GridSearchCV(model=model, param_grid = hyper_params, n_jobs=-1, cv=cv)\n",
    "    search.fit(X=x_train, y=y_train)\n",
    "    print(\"Best parameter (CV score=%0.3f):\\n\" % search.best_score_)\n",
    "    print(search.best_params_)\n",
    "    print(search.score) \n",
    "    return search\n",
    "\n",
    "\n",
    "def plot_grid_search(search_obj, pca_obj, X_train):\n",
    "    \n",
    "    \"\"\"\n",
    "    Prints the best (optimised) hyperparmatersfor the grid search object\n",
    "    and plots the optimised pca components\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Best parameter (CV score=%0.3f):\\n\" % search.best_score_)\n",
    "    print(\"Best Params:\",search.best_params_)\n",
    "    pca.fit(X_train_scaled)\n",
    "\n",
    "    fig, (ax0, ax1) = plt.subplots(nrows=2, sharex=True, figsize=(8, 8))\n",
    "    ax0.plot(np.arange(1, pca.n_components_ + 1),\n",
    "             pca.explained_variance_ratio_, '+', linewidth=2)\n",
    "    ax0.set_ylabel('PCA explained variance ratio')\n",
    "\n",
    "    ax0.axvline(search.best_estimator_.named_steps['pca'].n_components,\n",
    "                linestyle=':', label='n_components chosen')\n",
    "    ax0.legend(prop=dict(size=12))\n",
    "\n",
    "    # For each number of components, find the best classifier results\n",
    "    results = pd.DataFrame(search.cv_results_)\n",
    "    components_col = 'param_pca__n_components'\n",
    "    best_clfs = results.groupby(components_col).apply(\n",
    "        lambda g: g.nlargest(1, 'mean_test_score'))\n",
    "\n",
    "    best_clfs.plot(x=components_col, y='mean_test_score', yerr='std_test_score',\n",
    "                   legend=False, ax=ax1)\n",
    "    ax1.set_ylabel('Classification accuracy (val)')\n",
    "    ax1.set_xlabel('n_components')\n",
    "\n",
    "    plt.xlim(-1, 70)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show() \n",
    "    \n",
    "\n",
    "class metrics ():\n",
    "    \n",
    "    def __init__(self, y_test, y_hat):\n",
    "        pass\n",
    "        self.y_test = y_test\n",
    "        self.y_hat =  y_hat\n",
    "        \n",
    "    \n",
    "    def class_report(self):\n",
    "        \n",
    "        full_report = classification_report(self.y_test, self.y_hat)\n",
    "        \n",
    "        print(full_report)\n",
    "        \n",
    "    def conf_matrix(self):\n",
    "        \n",
    "        conf_matrix = confusion_matrix(self.y_test, self.y_hat)\n",
    "        \n",
    "        conf_matrix_df = pd.DataFrame(conf_matrix, columns=['Actual_+ve', 'Actual_-ve'],\n",
    "                               index=['predicted_+ve', 'predicted_-ve'])\n",
    "        \n",
    "        return conf_matrix_df\n",
    "    \n",
    "    def accuracy_score(self):\n",
    "        return  accuracy_score(self.y_test, self.y_hat)\n",
    "    \n",
    "    def classification_error(self):\n",
    "        \n",
    "        return 1 - accuracy_score() \n",
    "        \n",
    "    def specif_sensitiv(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        Sensitivity: When the actual value is positive, how often is the prediction correct?\n",
    "        \n",
    "        Specificity: When the actual value is negative, how often is the prediction correct?\n",
    "        \"\"\"\n",
    "        \n",
    "        conf_matrix = confusion_matrix(self.y_test, self.y_hat)\n",
    "        \n",
    "        TP = conf_matrix[1, 1]\n",
    "        TN = conf_matrix[0, 0]\n",
    "        FP = conf_matrix[0, 1]\n",
    "        FN = conf_matrix[1, 0]\n",
    "        \n",
    "        sensitivity = TP / float(FN + TP)\n",
    "        specificity = TN / (TN + FP)\n",
    "        \n",
    "        sensitiv_specific_table = pd.DataFrame([[sensitivity, specificity]],\n",
    "                                               columns=['sensitivity', 'specificity'])\n",
    "        \n",
    "        return sensitiv_specific_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV()"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogisticRegressionCV()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing model.py codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module Pipeline.py Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_termsheet_pred_model",
   "language": "python",
   "name": "venv_termsheet_pred_model"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
